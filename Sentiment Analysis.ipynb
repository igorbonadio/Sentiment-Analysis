{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisador de Sentimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1\n",
    "\n",
    "O objetivo deste _notebook_ é definir um método capaz de identificar se o sentimento expresso em um dado texto é positivo ou negativo. Utilizaremos _reviews_ de filmes extraídos do site [_Rotten Tomatoes_](https://www.rottentomatoes.com/) e baseados no _dataset_ disponível [neste site](http://www.cs.cornell.edu/people/pabo/movie-review-data/).\n",
    "\n",
    "Nossa __hipótese__ é que o significado de um texto está diretamente relacionado às palavras que o compõe. Para verificar esta hipóstese podemos analisar a frequência com que certas palavras são utilizadas. Palavras como _good_ e _best_ devem ser mais frequentes em _reviews_ positivos, já palavras como _bad_ e _worst_ devem ser mais utilizadas em _reviews_ negativos. Além de analizar a frequência de cada palavra, podemos verificar a frequência de conjuntos de palavras, já que, embora a expressão _not good_ contenha uma palvras positiva, seu real sentimento é negativo.\n",
    "\n",
    "Como consequência, assumiremos que, mesmo sem conhecer a estrutura sintática e/ou semântica de um texto é possível discriminá-lo entre sentimentos positivos e negativos. Mais ainda, assumiremos que nem mesmo a ordem em que as palavras aparecem importa. Esta é uma abordagem bastante utilizada e conhecida como _Bag of Words_ (_unigram_ para modelagens com palavras únicas e _n-gram_ para modelagens com conjuntos de palavras).\n",
    "\n",
    "### Pré-processamento\n",
    "\n",
    "A primeira etapa consistirá em construir um vocabulário $V = \\{w_1, w_2, ..., w_N\\}$, onde $w_i$ é uma palavra existente no conjunto de treinamento e que $w_i \\ne w_j$ para todo $i$ e $j$. \n",
    "\n",
    "### Representação\n",
    "\n",
    "Cada _review_ será representado como um vetor de tamanho $N$, sendo que cada posição $i$ conterá o número de vezes em que a palavra $w_i \\in V$ apareceu no dado _review_.\n",
    "\n",
    "### Modelagem\n",
    "\n",
    "Os _reviews_ podem ser classificados utilizando diversos modelos probabilisticos como regressão logística, árvores de decisão, random forest, SVM ou redes neurais. Neste _notebook_ decidimos utilizar redes neurais por ser uma técnica que vem apresentando bons resultados em diversas áreas, incluindo processamento de linguagem natural.\n",
    "\n",
    "Nossa rede neural terá uma camada de entrada, uma camada escondida e uma camada de saída, sendo que:\n",
    "\n",
    "* A camada de entrada terá tamanho $N$ já que nossos _reviews_ são representados por vetores de tamanho $N$. \n",
    "* A escolha por uma única camada escondida é arbitrária* e poderia ser melhor investigada. Mas devemos tomar cuidado com relação à esse número, pois redes neurais com número excessivo de camadas escondidas podem sofrer de _overfiting_.\n",
    "* A camada intermediária terá 20 neurônios. Este número também é arbitrário* e pode ser melhor investigado. Assim como o item anterior, aumentar excessivamente o número de neurônios pode levar a nossa rede a sofrer de _overfiting_.\n",
    "* A camada intermediária terá ativação _relu_, que vem sendo bastante utilizada e apresentando resultados melhores do que ativações mais clássicas como _sigmoids_. Ao utilizar _relu_ o cálculo das derivas (via backpropagation) é mais simples e mais rápido além de diminuir as chances de do gradiente sumir (como acontece com _sigmoids_ já que sua derivada tem como valor máximo 0.25)\n",
    "* A camada de saída terá 2 neurônios com ativação _softmax_, ou seja, apresentará a 'probabilidade' do _review_ ser classificado como positivo ou negativo.\n",
    "\n",
    "_* Para evitar escolhas arbitrária para o número de camadas escondidas e de neurônios, uma opção é utilizar alguma ténica de busca, que pode ser exaustiva ou até mesmo heurísticas de otimização como algoritmo genético._\n",
    "\n",
    "### Avaliação\n",
    "\n",
    "Para avaliarmos nosso modelo utilizaremos a técnica _k-fold cross-validation_, sendo $k=5$. Ou seja, dividiremos aleatoriamente o dataset em 5 partes de mesmo tamanho chamadas $d_1, d_2, d_3, d_4$ e $d_5$. Para $i = [1,k]$, treinaremos o modelo com todos os $d_j$ onde $j \\ne i$ e avaliaremos o modelo utilizando $d_i$.\n",
    "\n",
    "O método de avaliação que utilizaremos é a acurácia, ou seja, a porcentagem de _reviews_ corretamente rotulados. Neste caso, onde o número de _reviews_ positivos é o mesmo de _reviews_ negativos a acurácia é suficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando o Dataset\n",
    "\n",
    "Primeiramente vamos carregar os _reviews_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('dataset/rt-polarity.neg','r')\n",
    "negative_reviews = list(map(lambda x:x[:-1], f.readlines()))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('dataset/rt-polarity.pos','r')\n",
    "positive_reviews = list(map(lambda x:x[:-1], f.readlines()))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e juntá-los em um mesmo dataset único chamado `reviews`, bem como seus rótulos em `labels`:\n",
    "\n",
    "* 0 == NEGATIVE\n",
    "* 1 == POSITIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [0] * len(negative_reviews) + [1] * len(positive_reviews)\n",
    "reviews = negative_reviews + positive_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contêm 10662 reviews\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset contêm {} reviews\".format(len(reviews)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
