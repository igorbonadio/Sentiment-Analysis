{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisador de Sentimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1\n",
    "\n",
    "O objetivo deste _notebook_ é definir um método capaz de identificar se o sentimento expresso em um dado texto é positivo ou negativo. Utilizaremos _reviews_ de filmes extraídos do site [_Rotten Tomatoes_](https://www.rottentomatoes.com/) e baseados no _dataset_ disponível [neste site](http://www.cs.cornell.edu/people/pabo/movie-review-data/).\n",
    "\n",
    "Nossa __hipótese__ é que o significado de um texto está diretamente relacionado às palavras que o compõe. Para verificar esta hipótese podemos analisar a frequência com que certas palavras são utilizadas. Palavras como _good_ e _best_ devem ser mais frequentes em _reviews_ positivos, já palavras como _bad_ e _worst_ devem ser mais utilizadas em _reviews_ negativos. Além de analisar a frequência de cada palavra, podemos verificar a frequência de conjuntos de palavras, já que, embora a expressão _not good_ contenha uma palavra positiva, seu real sentimento é negativo.\n",
    "\n",
    "Como consequência, assumiremos que, mesmo sem conhecer a estrutura sintática e/ou semântica de um texto é possível discriminá-lo entre sentimentos positivos e negativos. Mais ainda, assumiremos que nem mesmo a ordem em que as palavras aparecem importa. Esta é uma abordagem bastante utilizada e conhecida como _Bag of Words_ (_unigram_ para modelagens com palavras únicas e _n-gram_ para modelagens com conjuntos de palavras) \\[[1](http://www.iosrjournals.org/iosr-jce/papers/Vol16-issue1/Version-5/F016153438.pdf?id=8590)]\\.\n",
    "\n",
    "### Pré-processamento\n",
    "\n",
    "A primeira etapa consistirá em construir um vocabulário $V = \\{w_1, w_2, ..., w_N\\}$, onde $w_i$ é uma palavra existente no conjunto de treinamento e que $w_i \\ne w_j$ para todo $i$ e $j$. \n",
    "\n",
    "### Representação\n",
    "\n",
    "Cada _review_ será representado como um vetor de tamanho $N$, sendo que cada posição $i$ conterá o número de vezes em que a palavra $w_i \\in V$ apareceu no dado _review_.\n",
    "\n",
    "### Modelagem\n",
    "\n",
    "Os _reviews_ podem ser classificados utilizando diversos modelos como regressão logística, árvores de decisão, random forest, SVM ou redes neurais. Neste _notebook_ decidimos utilizar redes neurais por ser uma técnica que vem apresentando bons resultados em diversas áreas, incluindo processamento de linguagem natural \\[[2](https://www.jair.org/media/4992/live-4992-9623-jair.pdf), [3](https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/11957/12160), [4](https://arxiv.org/pdf/1606.01781.pdf), [5](http://sigport.org/documents/sentiment-analysis-recurrent-neural-network-and-unsupervised-neural-language-model)\\].\n",
    "\n",
    "Nossa rede neural terá uma camada de entrada, uma camada escondida e uma camada de saída, sendo que:\n",
    "\n",
    "* A camada de entrada terá tamanho $N$ já que nossos _reviews_ são representados por vetores de tamanho $N$. \n",
    "* A escolha por uma única camada escondida é arbitrária* e poderia ser melhor investigada. Mas devemos tomar cuidado com relação à esse número, pois redes neurais com número excessivo de camadas escondidas podem sofrer de _overfiting_.\n",
    "* A camada intermediária terá 20 neurônios. Este número também é arbitrário* e pode ser melhor investigado. Assim como o item anterior, aumentar excessivamente o número de neurônios pode levar a nossa rede a sofrer de _overfiting_.\n",
    "* A camada intermediária terá ativação _relu_, que vem sendo bastante utilizada e apresentando resultados melhores do que ativações mais clássicas como _sigmoids_. Ao utilizar _relu_ o cálculo das derivas (via backpropagation) é mais simples e mais rápido além de diminuir as chances do gradiente sumir (como acontece com _sigmoids_ já que sua derivada tem como valor máximo 0.25 - ver figura abaixo)\n",
    "\n",
    "![Função sigmoid e sua derivada](sigmoid.png)\n",
    "\n",
    "<center>__Figura 1__: _Em azul temos a função sigmoid e em vermelho sua derivada_</center>\n",
    "\n",
    "* A camada de saída terá 2 neurônios com ativação _softmax_, ou seja, apresentará a 'probabilidade' do _review_ ser classificado como positivo ou negativo.\n",
    "\n",
    "_* Para evitar escolhas arbitrária para o número de camadas escondidas e de neurônios, uma opção é utilizar alguma ténica de busca, que pode ser exaustiva ou até mesmo heurísticas de otimização como algoritmo genético._\n",
    "\n",
    "### Avaliação\n",
    "\n",
    "Para avaliarmos nosso modelo utilizaremos a técnica _k-fold cross-validation_, sendo $k=5$. Ou seja, dividiremos aleatoriamente o dataset em 5 partes de mesmo tamanho chamadas $d_1, d_2, d_3, d_4$ e $d_5$. Para $i = [1,k]$, treinaremos o modelo com todos os $d_j$ onde $j \\ne i$ e avaliaremos o modelo utilizando $d_i$.\n",
    "\n",
    "O método de avaliação que utilizaremos é a acurácia, ou seja, a porcentagem de _reviews_ corretamente rotulados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando o Dataset\n",
    "\n",
    "Primeiramente vamos carregar os _reviews_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('dataset/rt-polarity.neg','r')\n",
    "negative_reviews = list(map(lambda x:x[:-1], f.readlines()))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('dataset/rt-polarity.pos','r')\n",
    "positive_reviews = list(map(lambda x:x[:-1], f.readlines()))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e juntá-los em um mesmo dataset único chamado `reviews`, bem como seus rótulos em `labels`:\n",
    "\n",
    "* 0 == NEGATIVE\n",
    "* 1 == POSITIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [0] * len(negative_reviews) + [1] * len(positive_reviews)\n",
    "reviews = negative_reviews + positive_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contêm 10662 reviews\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset contêm {} reviews\".format(len(reviews)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisando Features\n",
    "\n",
    "Agora vamos analisar como iremos extrair as _features_ de um texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos meus testes o melhor conjunto de features foi a utilização de features unigram (uma palavra) e bigram (duas palavras consecutivas) em conjunto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(content):\n",
    "    features = []\n",
    "    prev_word = None\n",
    "    for word in content.split(' '):\n",
    "        if word not in punctuation:\n",
    "            if prev_word is not None:\n",
    "                features.append(prev_word + \"|\" + word)\n",
    "                features.append(prev_word)\n",
    "                features.append(word)\n",
    "            prev_word = word\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos avaliar as features que extraímos contando quantas vezes cada feature aparece no dataset (classificadas como positivas ou negativas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_counter = Counter()\n",
    "negative_counter = Counter()\n",
    "total_counter = Counter()\n",
    "for content, label in zip(reviews, labels):\n",
    "    if label == 1:\n",
    "        for feature in extract_features(content):\n",
    "            positive_counter[feature] += 1\n",
    "            total_counter[feature] +=1\n",
    "    else:\n",
    "        for feature in extract_features(content):\n",
    "            negative_counter[feature] += 1\n",
    "            total_counter[feature] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 9487),\n",
       " ('and', 7096),\n",
       " ('a', 6923),\n",
       " ('of', 6620),\n",
       " ('to', 3925),\n",
       " ('is', 3390),\n",
       " ('in', 2623),\n",
       " ('that', 2503),\n",
       " ('it', 1988),\n",
       " ('with', 1721),\n",
       " ('as', 1687),\n",
       " ('but', 1557),\n",
       " ('film', 1554),\n",
       " ('its', 1378),\n",
       " ('an', 1336),\n",
       " ('for', 1300),\n",
       " ('this', 1168),\n",
       " ('movie', 972),\n",
       " ('you', 933),\n",
       " (\"it's\", 899),\n",
       " ('on', 835),\n",
       " ('be', 819),\n",
       " ('has', 744),\n",
       " ('by', 739),\n",
       " ('about', 715),\n",
       " ('at', 700),\n",
       " ('of|the', 699),\n",
       " ('not', 691),\n",
       " ('are', 691),\n",
       " ('from', 690)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_counter.most_common()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 9338),\n",
       " ('a', 6430),\n",
       " ('of', 5498),\n",
       " ('and', 5292),\n",
       " ('to', 4502),\n",
       " ('is', 3295),\n",
       " ('in', 2522),\n",
       " ('that', 2393),\n",
       " ('it', 2145),\n",
       " ('as', 1789),\n",
       " ('but', 1707),\n",
       " ('for', 1482),\n",
       " ('movie', 1427),\n",
       " ('this', 1368),\n",
       " ('with', 1313),\n",
       " ('its', 1248),\n",
       " ('film', 1190),\n",
       " ('an', 1028),\n",
       " ('be', 1020),\n",
       " ('on', 925),\n",
       " (\"it's\", 879),\n",
       " ('like', 839),\n",
       " ('not', 829),\n",
       " ('by', 815),\n",
       " ('more', 809),\n",
       " ('than', 764),\n",
       " ('you', 762),\n",
       " ('have', 727),\n",
       " ('are', 717),\n",
       " ('about', 715)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_counter.most_common()[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, as palavras mais comuns tanto no conjunto de _reviews_ positivos quanto no de negativos são parecidas. Isso já era esperado, já que a maior parte das palavras podem ser consideradas neutras.\n",
    "\n",
    "Para podermos observar quais as palavras que melhor caracterizam _reviews_ positivos e negativos devemos calcular a razão entre suas frequências:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_count = 20\n",
    "sentiment_ratio = Counter()\n",
    "for feature, n in list(total_counter.most_common()):\n",
    "    if(n > min_count):\n",
    "        sentiment_ratio[feature] = float(positive_counter[feature] + 1) / float(negative_counter[feature] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desta forma, podemos concluir que razões:\n",
    "\n",
    "* iguais (ou próximas) a 1: representam palavras que aparecem em _reviews_ positivos e negativos com a mesma (ou semelhante) frequência.\n",
    "* maiores do que 1: representam palavras que aparecem mais em _reviews_ positivos, e portanto caracterizam melhor esse tipo de _review_\n",
    "* menores do que 1: representam palavras que aparecem mais em _reviews_ negativos, e portanto caracterizam melhor esse tipo de _review_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('riveting', 40.0),\n",
       " ('gem', 32.0),\n",
       " ('wonderfully', 31.0),\n",
       " ('lively', 29.0),\n",
       " ('detailed', 27.0),\n",
       " ('heartwarming', 27.0),\n",
       " ('polished', 25.0),\n",
       " ('vividly', 25.0),\n",
       " ('startling', 23.0),\n",
       " ('tour', 23.0),\n",
       " ('spare', 22.0),\n",
       " ('heartbreaking', 22.0),\n",
       " ('engrossing', 20.333333333333332),\n",
       " ('mesmerizing', 15.5),\n",
       " ('inventive', 15.0),\n",
       " ('refreshingly', 13.0),\n",
       " ('what|makes', 13.0),\n",
       " ('refreshing', 12.666666666666666),\n",
       " ('wonderful', 12.6),\n",
       " ('warm', 12.4),\n",
       " ('realistic', 11.0),\n",
       " ('captures', 10.8),\n",
       " ('powerful', 10.11111111111111),\n",
       " ('provides', 10.0),\n",
       " ('wry', 9.666666666666666),\n",
       " ('touching', 9.625),\n",
       " ('tender', 9.333333333333334),\n",
       " ('unexpected', 9.2),\n",
       " ('a|compelling', 9.0),\n",
       " ('chilling', 9.0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_ratio.most_common()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unfunny', 0.02),\n",
       " ('badly', 0.02127659574468085),\n",
       " ('poorly', 0.02702702702702703),\n",
       " ('disguise', 0.029411764705882353),\n",
       " ('pointless', 0.03225806451612903),\n",
       " ('pinocchio', 0.037037037037037035),\n",
       " ('bore', 0.041666666666666664),\n",
       " ('uninspired', 0.041666666666666664),\n",
       " ('lousy', 0.041666666666666664),\n",
       " ('the|problem', 0.041666666666666664),\n",
       " ('plodding', 0.041666666666666664),\n",
       " ('lifeless', 0.043478260869565216),\n",
       " ('product', 0.043478260869565216),\n",
       " ('incoherent', 0.045454545454545456),\n",
       " ('flat', 0.056338028169014086),\n",
       " ('mediocre', 0.061224489795918366),\n",
       " ('mindless', 0.06451612903225806),\n",
       " ('generic', 0.06666666666666667),\n",
       " ('boring', 0.06741573033707865),\n",
       " ('routine', 0.07317073170731707),\n",
       " ('90', 0.075),\n",
       " ('disaster', 0.08),\n",
       " ('dull', 0.0873015873015873),\n",
       " ('supposed|to', 0.09523809523809523),\n",
       " ('ends|up', 0.09523809523809523),\n",
       " ('stale', 0.0967741935483871),\n",
       " ('tiresome', 0.1),\n",
       " ('stupid', 0.1),\n",
       " ('the|worst', 0.10256410256410256),\n",
       " ('offensive', 0.10344827586206896)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(reversed(sentiment_ratio.most_common()))[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como esperado, palavras como _wonderfully_ e _gem_ caracterizam _reviews_ positivos, e palavras como _unfunny_ e _badly_ caracterizam _reviews_ negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraindo Features\n",
    "\n",
    "Vamos definir algumas funções para facilitar a extração de features.\n",
    "\n",
    "Primeiramente, vamos definir a função `build_vocabulary` que retorna um vocabulário contendo todas as palavras dos `reviews` com frequência maior do que `cutoff`. Além disso, também retorna `feature2index` que será utilizado para encontrar o número do índice de uma dada feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_vocabulary(reviews, cutoff):\n",
    "    counter = Counter()\n",
    "    for content in reviews:\n",
    "        for feature in extract_features(content):\n",
    "            counter[feature] += 1\n",
    "    vocabulary = []\n",
    "    feature2index = Counter()\n",
    "    for f in counter.keys():\n",
    "        if counter[f] > cutoff:\n",
    "            vocabulary.append(f)\n",
    "            feature2index[f] = len(vocabulary) - 1\n",
    "    return (vocabulary, feature2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, vamos definir uma função que recebe um vocabulário e um conversor `feature2index` e transforma os _reviews_ em _Bags of Words_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dataset(reviews, vocabulary, feature2index):\n",
    "    feature_dataset = np.zeros((len(reviews), len(vocabulary)))\n",
    "    i = 0\n",
    "    for content in reviews:\n",
    "        for f in extract_features(content):\n",
    "            feature_dataset[i][feature2index[f]] += 1\n",
    "        i += 1\n",
    "    return feature_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir definimos uma função que constrói nossa rede neural completamente conectada:\n",
    "\n",
    "* Uma camada de entrada de tamanho N = tamanho do vocabulário\n",
    "* Uma camada oculta com 20 neurônios, com função de ativação ReLu\n",
    "* Uma camada de saída com 2 neurônios com função de ativação softmax\n",
    "\n",
    "Durante o treinamento, será otimizada a função `categorical_crossentropy`, utilizando o algoritmo de otimização `adam`. A cada iteração será apresentada a acurácia de predição do próprio conjunto de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=20, input_dim=len(vocabulary)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=2))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos o método _5-fold cross-validation_ para avaliar nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os hiper-parâmetros utilizados para o treinamento da rede neural são:\n",
    "\n",
    "* batch_size\n",
    "* epochs - O número de iterações escolhido foi de 10. Acima disso a rede parece iniciar a sofrer de overffiting\n",
    "* cutoff - A frequência mínima de uma palavra no conjunto de treinamento para que ela entre no vocabulario é de 20. Números menores do que esse melhoram o desempenho da rede neural, mas o tempo de execução aumenta bastante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 1/10\n",
      "8528/8528 [==============================] - 0s - loss: 0.6570 - acc: 0.6136     \n",
      "Epoch 2/10\n",
      "8528/8528 [==============================] - 0s - loss: 0.5514 - acc: 0.7462     \n",
      "Epoch 3/10\n",
      "8528/8528 [==============================] - 0s - loss: 0.4781 - acc: 0.7913     \n",
      "Epoch 4/10\n",
      "8528/8528 [==============================] - 0s - loss: 0.4276 - acc: 0.8168     \n",
      "Epoch 5/10\n",
      "8528/8528 [==============================] - 0s - loss: 0.3879 - acc: 0.8340     \n",
      "Epoch 6/10\n",
      "8528/8528 [==============================] - 0s - loss: 0.3576 - acc: 0.8494     \n",
      "Epoch 7/10\n",
      "8528/8528 [==============================] - 0s - loss: 0.3286 - acc: 0.8644     \n",
      "Epoch 8/10\n",
      "8528/8528 [==============================] - 0s - loss: 0.3015 - acc: 0.8790     \n",
      "Epoch 9/10\n",
      "8528/8528 [==============================] - 0s - loss: 0.2770 - acc: 0.8891     \n",
      "Epoch 10/10\n",
      "8528/8528 [==============================] - 0s - loss: 0.2556 - acc: 0.8985     \n",
      "Evaluating:\n",
      "1600/2134 [=====================>........] - ETA: 0s - loss: 0.6573731008822826 - acc: 0.7141518276097513\n",
      "******************************************************************\n",
      "Fold 2/5\n",
      "Epoch 1/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.6663 - acc: 0.6040     \n",
      "Epoch 2/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.5672 - acc: 0.7340     \n",
      "Epoch 3/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.4877 - acc: 0.7821     \n",
      "Epoch 4/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.4349 - acc: 0.8095     \n",
      "Epoch 5/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3961 - acc: 0.8245     \n",
      "Epoch 6/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3629 - acc: 0.8426     \n",
      "Epoch 7/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3269 - acc: 0.8626     \n",
      "Epoch 8/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.2954 - acc: 0.8785     \n",
      "Epoch 9/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.2627 - acc: 0.8986     \n",
      "Epoch 10/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.2331 - acc: 0.9154     \n",
      "Evaluating:\n",
      "1952/2132 [==========================>...] - ETA: 0s - loss: 0.614179367475617 - acc: 0.7401500936968018\n",
      "******************************************************************\n",
      "Fold 3/5\n",
      "Epoch 1/10\n",
      "8530/8530 [==============================] - 1s - loss: 0.6684 - acc: 0.6057     \n",
      "Epoch 2/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.5616 - acc: 0.7343     \n",
      "Epoch 3/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.4845 - acc: 0.7860     \n",
      "Epoch 4/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.4316 - acc: 0.8116     \n",
      "Epoch 5/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3945 - acc: 0.8284     \n",
      "Epoch 6/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3644 - acc: 0.8414     \n",
      "Epoch 7/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3373 - acc: 0.8572     \n",
      "Epoch 8/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3139 - acc: 0.8720     \n",
      "Epoch 9/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.2891 - acc: 0.8816     \n",
      "Epoch 10/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.2652 - acc: 0.9000     \n",
      "Evaluating:\n",
      "1600/2132 [=====================>........] - ETA: 0s - loss: 0.5968277338074475 - acc: 0.7321763601133121\n",
      "******************************************************************\n",
      "Fold 4/5\n",
      "Epoch 1/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.6674 - acc: 0.5992     \n",
      "Epoch 2/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.5549 - acc: 0.7394     \n",
      "Epoch 3/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.4757 - acc: 0.7844     \n",
      "Epoch 4/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.4270 - acc: 0.8138     \n",
      "Epoch 5/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3920 - acc: 0.8273     \n",
      "Epoch 6/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3611 - acc: 0.8450     \n",
      "Epoch 7/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3344 - acc: 0.8596     \n",
      "Epoch 8/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3073 - acc: 0.8726     \n",
      "Epoch 9/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.2846 - acc: 0.8858     \n",
      "Epoch 10/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.2623 - acc: 0.8973     \n",
      "Evaluating:\n",
      "1824/2132 [========================>.....] - ETA: 0s - loss: 0.6212490430245032 - acc: 0.733114446584995\n",
      "******************************************************************\n",
      "Fold 5/5\n",
      "Epoch 1/10\n",
      "8530/8530 [==============================] - 1s - loss: 0.6659 - acc: 0.6076     \n",
      "Epoch 2/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.5511 - acc: 0.7424     \n",
      "Epoch 3/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.4762 - acc: 0.7870     \n",
      "Epoch 4/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.4275 - acc: 0.8108     \n",
      "Epoch 5/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3910 - acc: 0.8273     \n",
      "Epoch 6/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3593 - acc: 0.8441     \n",
      "Epoch 7/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3297 - acc: 0.8601     \n",
      "Epoch 8/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.2966 - acc: 0.8771     - ETA: 0s - loss: 0.3033 - acc\n",
      "Epoch 9/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.2701 - acc: 0.8959     \n",
      "Epoch 10/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.2445 - acc: 0.9077     \n",
      "Evaluating:\n",
      "1632/2132 [=====================>........] - ETA: 0s - loss: 0.6130071632969446 - acc: 0.7317073169613422\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "cutoff = 20\n",
    "\n",
    "X = np.array(reviews)\n",
    "y = np.array(labels)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "evaluations = []\n",
    "k = 1\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "    \n",
    "    vocabulary, feature2index = build_vocabulary(X_train, cutoff)\n",
    "    X_train = build_dataset(X_train, vocabulary, feature2index)\n",
    "    y_train = keras.utils.to_categorical(y_train, 2)\n",
    "    X_test = build_dataset(X_test, vocabulary, feature2index)\n",
    "    y_test = keras.utils.to_categorical(y_test, 2)\n",
    "    \n",
    "    model = create_model()\n",
    "    print(\"Fold {}/5\".format(k))\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, verbose=1, epochs=epochs)\n",
    "    print(\"Evaluating:\")\n",
    "    result = model.evaluate(X_test, y_test)\n",
    "    evaluations.append(result[1])\n",
    "    print(\" - loss: {} - acc: {}\".format(result[0], result[1]))\n",
    "    print(\"******************************************************************\")\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média 0.7302600089932405 +/- 0.008616289211280678\n"
     ]
    }
   ],
   "source": [
    "print(\"Acurácia média {} +/- {}\".format(np.array(evaluations).mean(), np.array(evaluations).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
