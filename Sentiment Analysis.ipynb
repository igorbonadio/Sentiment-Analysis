{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisador de Sentimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1\n",
    "\n",
    "O objetivo deste _notebook_ é definir um método capaz de identificar se o sentimento expresso em um dado texto é positivo ou negativo. Utilizaremos _reviews_ de filmes extraídos do site [_Rotten Tomatoes_](https://www.rottentomatoes.com/) e baseados no _dataset_ disponível [neste site](http://www.cs.cornell.edu/people/pabo/movie-review-data/).\n",
    "\n",
    "Nossa __hipótese__ é que o significado de um texto está diretamente relacionado às palavras que o compõe. Para verificar esta hipóstese podemos analisar a frequência com que certas palavras são utilizadas. Palavras como _good_ e _best_ devem ser mais frequentes em _reviews_ positivos, já palavras como _bad_ e _worst_ devem ser mais utilizadas em _reviews_ negativos. Além de analizar a frequência de cada palavra, podemos verificar a frequência de conjuntos de palavras, já que, embora a expressão _not good_ contenha uma palvras positiva, seu real sentimento é negativo.\n",
    "\n",
    "Como consequência, assumiremos que, mesmo sem conhecer a estrutura sintática e/ou semântica de um texto é possível discriminá-lo entre sentimentos positivos e negativos. Mais ainda, assumiremos que nem mesmo a ordem em que as palavras aparecem importa. Esta é uma abordagem bastante utilizada e conhecida como _Bag of Words_ (_unigram_ para modelagens com palavras únicas e _n-gram_ para modelagens com conjuntos de palavras).\n",
    "\n",
    "### Pré-processamento\n",
    "\n",
    "A primeira etapa consistirá em construir um vocabulário $V = \\{w_1, w_2, ..., w_N\\}$, onde $w_i$ é uma palavra existente no conjunto de treinamento e que $w_i \\ne w_j$ para todo $i$ e $j$. \n",
    "\n",
    "### Representação\n",
    "\n",
    "Cada _review_ será representado como um vetor de tamanho $N$, sendo que cada posição $i$ conterá o número de vezes em que a palavra $w_i \\in V$ apareceu no dado _review_.\n",
    "\n",
    "### Modelagem\n",
    "\n",
    "Os _reviews_ podem ser classificados utilizando diversos modelos probabilisticos como regressão logística, árvores de decisão, random forest, SVM ou redes neurais. Neste _notebook_ decidimos utilizar redes neurais por ser uma técnica que vem apresentando bons resultados em diversas áreas, incluindo processamento de linguagem natural.\n",
    "\n",
    "Nossa rede neural terá uma camada de entrada, uma camada escondida e uma camada de saída, sendo que:\n",
    "\n",
    "* A camada de entrada terá tamanho $N$ já que nossos _reviews_ são representados por vetores de tamanho $N$. \n",
    "* A escolha por uma única camada escondida é arbitrária* e poderia ser melhor investigada. Mas devemos tomar cuidado com relação à esse número, pois redes neurais com número excessivo de camadas escondidas podem sofrer de _overfiting_.\n",
    "* A camada intermediária terá 20 neurônios. Este número também é arbitrário* e pode ser melhor investigado. Assim como o item anterior, aumentar excessivamente o número de neurônios pode levar a nossa rede a sofrer de _overfiting_.\n",
    "* A camada intermediária terá ativação _relu_, que vem sendo bastante utilizada e apresentando resultados melhores do que ativações mais clássicas como _sigmoids_. Ao utilizar _relu_ o cálculo das derivas (via backpropagation) é mais simples e mais rápido além de diminuir as chances de do gradiente sumir (como acontece com _sigmoids_ já que sua derivada tem como valor máximo 0.25)\n",
    "* A camada de saída terá 2 neurônios com ativação _softmax_, ou seja, apresentará a 'probabilidade' do _review_ ser classificado como positivo ou negativo.\n",
    "\n",
    "_* Para evitar escolhas arbitrária para o número de camadas escondidas e de neurônios, uma opção é utilizar alguma ténica de busca, que pode ser exaustiva ou até mesmo heurísticas de otimização como algoritmo genético._\n",
    "\n",
    "### Avaliação\n",
    "\n",
    "Para avaliarmos nosso modelo utilizaremos a técnica _k-fold cross-validation_, sendo $k=5$. Ou seja, dividiremos aleatoriamente o dataset em 5 partes de mesmo tamanho chamadas $d_1, d_2, d_3, d_4$ e $d_5$. Para $i = [1,k]$, treinaremos o modelo com todos os $d_j$ onde $j \\ne i$ e avaliaremos o modelo utilizando $d_i$.\n",
    "\n",
    "O método de avaliação que utilizaremos é a acurácia, ou seja, a porcentagem de _reviews_ corretamente rotulados. Neste caso, onde o número de _reviews_ positivos é o mesmo de _reviews_ negativos a acurácia é suficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando o Dataset\n",
    "\n",
    "Primeiramente vamos carregar os _reviews_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('dataset/rt-polarity.neg','r')\n",
    "negative_reviews = list(map(lambda x:x[:-1], f.readlines()))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('dataset/rt-polarity.pos','r')\n",
    "positive_reviews = list(map(lambda x:x[:-1], f.readlines()))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e juntá-los em um mesmo dataset único chamado `reviews`, bem como seus rótulos em `labels`:\n",
    "\n",
    "* 0 == NEGATIVE\n",
    "* 1 == POSITIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [0] * len(negative_reviews) + [1] * len(positive_reviews)\n",
    "reviews = negative_reviews + positive_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contêm 10662 reviews\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset contêm {} reviews\".format(len(reviews)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisando Features\n",
    "\n",
    "Agora analisar como iremos extrair as _features_ de um texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos meus testes o melhor conjunto de features foi a utilização de features unigram (uma palavra) e bigram (duas palavras consecutivas) em conjunto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(content):\n",
    "    features = []\n",
    "    prev_word = None\n",
    "    for word in content.split(' '):\n",
    "        if word not in punctuation:\n",
    "            if prev_word is not None:\n",
    "                features.append(prev_word + \"|\" + word)\n",
    "                features.append(prev_word)\n",
    "                features.append(word)\n",
    "            prev_word = word\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos avaliar as features que extraímos contando quantas vezes cada feature aparece no dataset (classificadas como positivas ou negativas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive_counter = Counter()\n",
    "negative_counter = Counter()\n",
    "total_counter = Counter()\n",
    "for content, label in zip(reviews, labels):\n",
    "    if label == 1:\n",
    "        for feature in extract_features(content):\n",
    "            positive_counter[feature] += 1\n",
    "            total_counter[feature] +=1\n",
    "    else:\n",
    "        for feature in extract_features(content):\n",
    "            negative_counter[feature] += 1\n",
    "            total_counter[feature] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 9487),\n",
       " ('and', 7096),\n",
       " ('a', 6923),\n",
       " ('of', 6620),\n",
       " ('to', 3925),\n",
       " ('is', 3390),\n",
       " ('in', 2623),\n",
       " ('that', 2503),\n",
       " ('it', 1988),\n",
       " ('with', 1721),\n",
       " ('as', 1687),\n",
       " ('but', 1557),\n",
       " ('film', 1554),\n",
       " ('its', 1378),\n",
       " ('an', 1336),\n",
       " ('for', 1300),\n",
       " ('this', 1168),\n",
       " ('movie', 972),\n",
       " ('you', 933),\n",
       " (\"it's\", 899),\n",
       " ('on', 835),\n",
       " ('be', 819),\n",
       " ('has', 744),\n",
       " ('by', 739),\n",
       " ('about', 715),\n",
       " ('at', 700),\n",
       " ('of|the', 699),\n",
       " ('not', 691),\n",
       " ('are', 691),\n",
       " ('from', 690)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_counter.most_common()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 9338),\n",
       " ('a', 6430),\n",
       " ('of', 5498),\n",
       " ('and', 5292),\n",
       " ('to', 4502),\n",
       " ('is', 3295),\n",
       " ('in', 2522),\n",
       " ('that', 2393),\n",
       " ('it', 2145),\n",
       " ('as', 1789),\n",
       " ('but', 1707),\n",
       " ('for', 1482),\n",
       " ('movie', 1427),\n",
       " ('this', 1368),\n",
       " ('with', 1313),\n",
       " ('its', 1248),\n",
       " ('film', 1190),\n",
       " ('an', 1028),\n",
       " ('be', 1020),\n",
       " ('on', 925),\n",
       " (\"it's\", 879),\n",
       " ('like', 839),\n",
       " ('not', 829),\n",
       " ('by', 815),\n",
       " ('more', 809),\n",
       " ('than', 764),\n",
       " ('you', 762),\n",
       " ('have', 727),\n",
       " ('are', 717),\n",
       " ('about', 715)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_counter.most_common()[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, as palavras mais comuns tanto no conjunto de _reviews_ positivos quanto no de negativos são parecidas. Isso já era esperado, já que a maior parte das palavras podem ser consideradas neutras.\n",
    "\n",
    "Para podermos observar quais as palavras que melhor caracterizam _reviews_ positivos e negativos devemos calcular a razão entre suas frequências:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_count = 20\n",
    "sentiment_ratio = Counter()\n",
    "for feature, n in list(total_counter.most_common()):\n",
    "    if(n > min_count):\n",
    "        sentiment_ratio[feature] = float(positive_counter[feature] + 1) / float(negative_counter[feature] + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desta forma, podemos concluir que razões:\n",
    "\n",
    "* iguais (ou próximas) a 1: representam palavras que aparecem em _reviews_ positivos e negativos com a mesma (ou semelhante) frequência.\n",
    "* maiores do que 1: representam palavras que aparecem mais em _reviews_ positivos, e portanto caracterizam melhor esse tipo de _review_\n",
    "* menores do que 1: representam palavras que aparecem mais em _reviews_ negativos, e portanto caracterizam melhor esse tipo de _review_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('riveting', 40.0),\n",
       " ('gem', 32.0),\n",
       " ('wonderfully', 31.0),\n",
       " ('lively', 29.0),\n",
       " ('detailed', 27.0),\n",
       " ('heartwarming', 27.0),\n",
       " ('polished', 25.0),\n",
       " ('vividly', 25.0),\n",
       " ('startling', 23.0),\n",
       " ('tour', 23.0),\n",
       " ('spare', 22.0),\n",
       " ('heartbreaking', 22.0),\n",
       " ('engrossing', 20.333333333333332),\n",
       " ('mesmerizing', 15.5),\n",
       " ('inventive', 15.0),\n",
       " ('refreshingly', 13.0),\n",
       " ('what|makes', 13.0),\n",
       " ('refreshing', 12.666666666666666),\n",
       " ('wonderful', 12.6),\n",
       " ('warm', 12.4),\n",
       " ('realistic', 11.0),\n",
       " ('captures', 10.8),\n",
       " ('powerful', 10.11111111111111),\n",
       " ('provides', 10.0),\n",
       " ('wry', 9.666666666666666),\n",
       " ('touching', 9.625),\n",
       " ('tender', 9.333333333333334),\n",
       " ('unexpected', 9.2),\n",
       " ('a|compelling', 9.0),\n",
       " ('chilling', 9.0)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_ratio.most_common()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('unfunny', 0.02),\n",
       " ('badly', 0.02127659574468085),\n",
       " ('poorly', 0.02702702702702703),\n",
       " ('disguise', 0.029411764705882353),\n",
       " ('pointless', 0.03225806451612903),\n",
       " ('pinocchio', 0.037037037037037035),\n",
       " ('bore', 0.041666666666666664),\n",
       " ('uninspired', 0.041666666666666664),\n",
       " ('lousy', 0.041666666666666664),\n",
       " ('the|problem', 0.041666666666666664),\n",
       " ('plodding', 0.041666666666666664),\n",
       " ('lifeless', 0.043478260869565216),\n",
       " ('product', 0.043478260869565216),\n",
       " ('incoherent', 0.045454545454545456),\n",
       " ('flat', 0.056338028169014086),\n",
       " ('mediocre', 0.061224489795918366),\n",
       " ('mindless', 0.06451612903225806),\n",
       " ('generic', 0.06666666666666667),\n",
       " ('boring', 0.06741573033707865),\n",
       " ('routine', 0.07317073170731707),\n",
       " ('90', 0.075),\n",
       " ('disaster', 0.08),\n",
       " ('dull', 0.0873015873015873),\n",
       " ('supposed|to', 0.09523809523809523),\n",
       " ('ends|up', 0.09523809523809523),\n",
       " ('stale', 0.0967741935483871),\n",
       " ('tiresome', 0.1),\n",
       " ('stupid', 0.1),\n",
       " ('the|worst', 0.10256410256410256),\n",
       " ('offensive', 0.10344827586206896)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(reversed(sentiment_ratio.most_common()))[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como esperado, palavras como _wonderfully_ e _gem_ caracterizam _reviews_ positivos, e palavras como _unfunny_ e _badly_ caracterizam _reviews_ negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraindo Features\n",
    "\n",
    "Vamos definir algumas funções para facilitar a extração de features.\n",
    "\n",
    "Primeiramente, vamos definir a função `build_vocabulary` que retorna um vocabulário contendo todas palavras de `reviews` com frequência maior do que `cutoff`. Além disso, também retorna `feature2index` que será utilizado para encontrar o número do índice de uma dada feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vocabulary_to_index(vocabulary):\n",
    "    feature2index = Counter()\n",
    "    for i, feature in enumerate(vocabulary):\n",
    "        feature2index[feature] = i\n",
    "    return feature2index\n",
    "\n",
    "def build_vocabulary(reviews, cutoff):\n",
    "    counter = Counter()\n",
    "    for content in reviews:\n",
    "        for feature in extract_features(content):\n",
    "            counter[feature] += 1\n",
    "    vocabulary = {}\n",
    "    for f in counter.keys():\n",
    "        if counter[f] > cutoff:\n",
    "            vocabulary[f] = 1\n",
    "    return (vocabulary.keys(), vocabulary_to_index(vocabulary.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, vamos definir uma função que recebe um vocabulário e um conversor `feature2index` e transforma os _reviews_ em _Bags of Words_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_dataset(reviews, vocabulary, feature2index):\n",
    "    feature_dataset = np.zeros((len(reviews), len(vocabulary)))\n",
    "    i = 0\n",
    "    for content in reviews:\n",
    "        for f in extract_features(content):\n",
    "            feature_dataset[i][feature2index[f]] += 1\n",
    "        i += 1\n",
    "    return feature_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementando o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir definimos uma função que constroi nossa rede neural completamente conectada:\n",
    "\n",
    "* Uma camada de entrada de tamanho N = tamanho do vocabulário\n",
    "* Uma camada oculta com 20 neurônios, com função de ativação ReLu\n",
    "* Uma camada de saída com 2 neurônios com função de ativação softmax\n",
    "\n",
    "Durante o treinamento, será otimizada a função `categorical_crossentropy`, utilizando o algoritmo de otimzação `adam`. A cada iteração será apresentada a acurácia de predição do próprio conjunto de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=20, input_dim=len(vocabulary)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(units=2))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos o método _5-fold cross-validation_ para avaliar nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os hiper-parâmetros utilizados para o treinamento da rede neural são:\n",
    "\n",
    "* batch_size\n",
    "* epochs - O número de iterações escolhido foi de 10. Acima disso a rede parece iniciar a sofrer de overffiting\n",
    "* cutoff - A frequência mínima de uma palavra no conjunto de treinamento para que ela entre no vocabulario é de 20. Números menores do que esse melhoram o desempenho da rede neural, mas o tempo de execução aumenta bastante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 1/10\n",
      "8528/8528 [==============================] - 1s - loss: 0.6693 - acc: 0.5974     \n",
      "Epoch 2/10\n",
      "8528/8528 [==============================] - 0s - loss: 0.5664 - acc: 0.7329     \n",
      "Epoch 3/10\n",
      "8528/8528 [==============================] - 0s - loss: 0.4866 - acc: 0.7797     \n",
      "Epoch 4/10\n",
      "8528/8528 [==============================] - 0s - loss: 0.4377 - acc: 0.8045     \n",
      "Epoch 5/10\n",
      "8528/8528 [==============================] - 0s - loss: 0.4059 - acc: 0.8180     \n",
      "Epoch 6/10\n",
      "8528/8528 [==============================] - 0s - loss: 0.3743 - acc: 0.8341     \n",
      "Epoch 7/10\n",
      "8528/8528 [==============================] - 0s - loss: 0.3498 - acc: 0.8464     \n",
      "Epoch 8/10\n",
      "8528/8528 [==============================] - 0s - loss: 0.3241 - acc: 0.8610     \n",
      "Epoch 9/10\n",
      "8528/8528 [==============================] - 0s - loss: 0.3027 - acc: 0.8712     \n",
      "Epoch 10/10\n",
      "8528/8528 [==============================] - 0s - loss: 0.2822 - acc: 0.8847     \n",
      "Evaluating:\n",
      "1920/2134 [=========================>....] - ETA: 0s - loss: 0.591274200529279 - acc: 0.7305529520907129\n",
      "******************************************************************\n",
      "Fold 2/5\n",
      "Epoch 1/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.6492 - acc: 0.6256     \n",
      "Epoch 2/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.5452 - acc: 0.7427     \n",
      "Epoch 3/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.4721 - acc: 0.7952     \n",
      "Epoch 4/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.4195 - acc: 0.8171     \n",
      "Epoch 5/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3746 - acc: 0.8392     \n",
      "Epoch 6/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3361 - acc: 0.8592     \n",
      "Epoch 7/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3008 - acc: 0.8803     \n",
      "Epoch 8/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.2717 - acc: 0.8943     \n",
      "Epoch 9/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.2406 - acc: 0.9097     \n",
      "Epoch 10/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.2127 - acc: 0.9249     \n",
      "Evaluating:\n",
      "1728/2132 [=======================>......] - ETA: 0s - loss: 0.6197186678256595 - acc: 0.7326454034889393\n",
      "******************************************************************\n",
      "Fold 3/5\n",
      "Epoch 1/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.6985 - acc: 0.5846     \n",
      "Epoch 2/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.5849 - acc: 0.7281     \n",
      "Epoch 3/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.5023 - acc: 0.7700     \n",
      "Epoch 4/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.4427 - acc: 0.8026     \n",
      "Epoch 5/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.4012 - acc: 0.8256     \n",
      "Epoch 6/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3682 - acc: 0.8437     \n",
      "Epoch 7/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3348 - acc: 0.8585     \n",
      "Epoch 8/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3083 - acc: 0.8733     \n",
      "Epoch 9/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.2820 - acc: 0.8891     \n",
      "Epoch 10/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.2565 - acc: 0.9018     \n",
      "Evaluating:\n",
      "1504/2132 [====================>.........] - ETA: 0s - loss: 0.5875906554552225 - acc: 0.7429643526086217\n",
      "******************************************************************\n",
      "Fold 4/5\n",
      "Epoch 1/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.6823 - acc: 0.6023     \n",
      "Epoch 2/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.5430 - acc: 0.7453     \n",
      "Epoch 3/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.4751 - acc: 0.7814     \n",
      "Epoch 4/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.4238 - acc: 0.8151     \n",
      "Epoch 5/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3846 - acc: 0.8376     \n",
      "Epoch 6/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3514 - acc: 0.8558     \n",
      "Epoch 7/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3212 - acc: 0.8688     \n",
      "Epoch 8/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.2922 - acc: 0.8841     \n",
      "Epoch 9/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.2677 - acc: 0.8977     \n",
      "Epoch 10/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.2421 - acc: 0.9097     \n",
      "Evaluating:\n",
      "2048/2132 [===========================>..] - ETA: 0s - loss: 0.6383344777082189 - acc: 0.7195121950101226\n",
      "******************************************************************\n",
      "Fold 5/5\n",
      "Epoch 1/10\n",
      "8530/8530 [==============================] - 1s - loss: 0.6893 - acc: 0.5856     \n",
      "Epoch 2/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.5640 - acc: 0.7345     \n",
      "Epoch 3/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.4806 - acc: 0.7832     \n",
      "Epoch 4/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.4317 - acc: 0.8070     \n",
      "Epoch 5/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3971 - acc: 0.8225     \n",
      "Epoch 6/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3666 - acc: 0.8414     \n",
      "Epoch 7/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3423 - acc: 0.8547     \n",
      "Epoch 8/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.3180 - acc: 0.8634     \n",
      "Epoch 9/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.2995 - acc: 0.8764     \n",
      "Epoch 10/10\n",
      "8530/8530 [==============================] - 0s - loss: 0.2765 - acc: 0.8879     \n",
      "Evaluating:\n",
      "1440/2132 [===================>..........] - ETA: 0s - loss: 0.611046148509514 - acc: 0.7204502815377198\n",
      "******************************************************************\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "cutoff = 20\n",
    "\n",
    "X = np.array(reviews)\n",
    "y = np.array(labels)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "evaluations = []\n",
    "k = 1\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "    \n",
    "    vocabulary, feature2index = build_vocabulary(X_train, cutoff)\n",
    "    X_train = build_dataset(X_train, vocabulary, feature2index)\n",
    "    y_train = keras.utils.to_categorical(y_train, 2)\n",
    "    X_test = build_dataset(X_test, vocabulary, feature2index)\n",
    "    y_test = keras.utils.to_categorical(y_test, 2)\n",
    "    \n",
    "    model = create_model()\n",
    "    print(\"Fold {}/5\".format(k))\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, verbose=1, epochs=epochs)\n",
    "    print(\"Evaluating:\")\n",
    "    result = model.evaluate(X_test, y_test)\n",
    "    evaluations.append(result[1])\n",
    "    print(\" - loss: {} - acc: {}\".format(result[0], result[1]))\n",
    "    print(\"******************************************************************\")\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média 0.7292250369472233 +/- 0.008643687774824561\n"
     ]
    }
   ],
   "source": [
    "print(\"Acurácia média {} +/- {}\".format(np.array(evaluations).mean(), np.array(evaluations).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
